{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrainModelSemanticSegmentation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lTNYV5UCWyz"
      },
      "source": [
        "Import the needed packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4RyYeaazyGF"
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D,BatchNormalization,Activation,Dropout,concatenate,Input\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from tensorflow import metrics\n",
        "from tensorflow.keras import optimizers\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import glob"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjuTNDIdq1cB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "351c0c97-e6c8-497c-f2d9-0d8799aefb5b"
      },
      "source": [
        "#Mount the Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LQRjmobCc4X"
      },
      "source": [
        "Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NN80312mQZ8L"
      },
      "source": [
        "def get_train_data():\n",
        "  img_directory=\"/content/drive/MyDrive/Kaggle/people_segmentation\"\n",
        "  mask_directory=\"/content/drive/MyDrive/Kaggle/people_segmentation\"\n",
        "  images=[]\n",
        "  masks=[]\n",
        "  for img_path in sorted(glob.glob(os.path.join(img_directory, \"images/*\"))):\n",
        "      print(img_path)\n",
        "      image = cv2.imread(img_path,cv2.IMREAD_COLOR) \n",
        "      image= cv2.resize(image, (256, 256))\n",
        "      #image=image/255 \n",
        "      images.append(image)\n",
        "\n",
        "  for img_path in sorted(glob.glob(os.path.join(mask_directory, \"masks/*\"))):\n",
        "      print(img_path)\n",
        "      image = cv2.imread(img_path,0) \n",
        "      image= cv2.resize(image, (256, 256))\n",
        "      masks.append(image)\n",
        "\n",
        "  #converting list to numpy array\n",
        "  images=np.array(images,dtype=\"float32\")\n",
        "  images= images / 255.0\n",
        "  \n",
        "  masks=np.array(masks,dtype=\"float32\")\n",
        "  masks[masks>0.5]=1\n",
        "  masks[masks<=0.5]=0\n",
        "  #expanding the array dimension \n",
        "  masks=np.expand_dims(masks, axis= -1)\n",
        "\n",
        "  print(images.shape)\n",
        "  print(masks.shape)\n",
        "\n",
        "  #spliting the data\n",
        "  X_train,X_val,y_train,y_val=train_test_split(images,masks,test_size=0.2,random_state=42)\n",
        "  return X_train,X_val,y_train,y_val"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUtpmBIyCoQI"
      },
      "source": [
        "Unet model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_wt0JLeJlzT"
      },
      "source": [
        "#function for two conolution\n",
        "def conv2d_block(input_img,filter_size):\n",
        "  #first convolution\n",
        "  x=Conv2D(filter_size,(3,3),kernel_initializer=\"he_normal\",padding=\"same\")(input_img)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Activation(\"relu\")(x)\n",
        "\n",
        "  #second convolution\n",
        "  x=Conv2D(filter_size,(3,3),kernel_initializer=\"he_normal\",padding=\"same\")(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Activation(\"relu\")(x)\n",
        "  return x"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vR1DQPfAJmlT"
      },
      "source": [
        "def UNet(input_img,n_filters=16):\n",
        "  #downsamping\n",
        "  c1=conv2d_block(input_img,n_filters*1)\n",
        "  p1=MaxPooling2D(2,2)(c1)\n",
        "  d1=Dropout(0.2)(p1)\n",
        "\n",
        "  c2=conv2d_block(d1,n_filters*2)\n",
        "  p2=MaxPooling2D(2,2)(c2)\n",
        "  d2=Dropout(0.2)(p2)\n",
        "\n",
        "  c3=conv2d_block(d2,n_filters*4)\n",
        "  p3=MaxPooling2D(2,2)(c3)\n",
        "  d3=Dropout(0.2)(p3)\n",
        "\n",
        "  c4=conv2d_block(d3,n_filters*8)\n",
        "  p4=MaxPooling2D(2,2)(c4)\n",
        "  d4=Dropout(0.2)(p4)\n",
        "\n",
        "  c5=conv2d_block(d4,n_filters*16)\n",
        "  #upsampling\n",
        "\n",
        "  t6=Conv2DTranspose(n_filters*8,(3,3),strides=(2,2),padding=\"same\")(c5)\n",
        "  j6=concatenate([t6,c4])\n",
        "  d6=Dropout(0.2)(j6)\n",
        "  c6=conv2d_block(d6,n_filters*8)\n",
        "  \n",
        "  t7=Conv2DTranspose(n_filters*4,(3,3),strides=(2,2),padding=\"same\")(c6)\n",
        "  j7=concatenate([t7,c3])\n",
        "  d7=Dropout(0.2)(j7)\n",
        "  c7=conv2d_block(d7,n_filters*4)\n",
        "\n",
        "  t8=Conv2DTranspose(n_filters*2,(3,3),strides=(2,2),padding=\"same\")(c7)\n",
        "  j8=concatenate([t8,c2])\n",
        "  d8=Dropout(0.2)(j8)\n",
        "  c8=conv2d_block(d8,n_filters*2)\n",
        "\n",
        "  t9=Conv2DTranspose(n_filters*1,(3,3),strides=(2,2),padding=\"same\")(c8)\n",
        "  j9=concatenate([t9,c1])\n",
        "  d9=Dropout(0.2)(j9)\n",
        "  c9=conv2d_block(d9,n_filters*1)\n",
        "\n",
        "  outputs=Conv2D(1,1,activation=\"sigmoid\")(c9)\n",
        "  model=Model(inputs=input_img,outputs=outputs)\n",
        "  return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24knOTaxCgI5"
      },
      "source": [
        "Creating function for dice coef and dice loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGpwXYv5Jvmc"
      },
      "source": [
        "def dice_coef(y_true,y_pred,smooth=1):\n",
        "  intersection = tf.keras.backend.sum(y_true * y_pred, axis=[1,2,3])\n",
        "  union = tf.keras.backend.sum(y_true, axis=[1,2,3]) + tf.keras.backend.sum(y_pred, axis=[1,2,3])\n",
        "  return tf.keras.backend.mean( (2. * intersection + smooth) / (union + smooth), axis=0)\n",
        "def dice_coef_loss(y_true,y_pred):\n",
        "  loss=dice_coef(y_true,y_pred)\n",
        "  return -loss"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lBvWYmxKeyD"
      },
      "source": [
        "#function to create the model\n",
        "def get_model():\n",
        "  input_img = Input((256,256, 3), name='img')\n",
        "  model=UNet(input_img,n_filters=64)\n",
        "  model.compile(optimizer=optimizers.Adam(1e-4), loss=dice_coef_loss, metrics=[\n",
        "                                                                     dice_coef, \n",
        "                                                                     metrics.Recall(),\n",
        "                                                                     metrics.Precision()\n",
        "                                                                     ])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTlmKxw5D3Pp"
      },
      "source": [
        "Main function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CAfzl_8MlY1"
      },
      "source": [
        "def run():\n",
        "  #get train and validation data\n",
        "  X_train,X_val,y_train,y_val=get_train_data()\n",
        "\n",
        "  #get the model\n",
        "  model=get_model()\n",
        "\n",
        "  callback=[\n",
        "          EarlyStopping(monitor=\"val_loss\",patience=10),\n",
        "          ModelCheckpoint('model.h5',monitor=\"val_loss\", save_best_only=True, verbose=1),\n",
        "          ReduceLROnPlateau(monitor=\"val_loss\",factor=0.1,patience=5,min_lr=0.0000001,verbose=1)\n",
        "          #CSVLogger()\n",
        "                  \n",
        "  ]\n",
        "  #fit the model\n",
        "  model.fit(X_train, y_train,batch_size=8,epochs=100,callbacks=callback,validation_data=(X_val,y_val))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phWZhfMTKiPp"
      },
      "source": [
        "#execute this to run the program\n",
        "run()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTPPW4eptx_M"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}